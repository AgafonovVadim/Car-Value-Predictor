pip install -U pandas



import pandas as pd



def clone(element):
    return lx.etree.fromstring(lx.etree.tostring(element))


pip install lxml


import lxml.html as lx
import requests


url = 'https://www.classic.com/search/?layout=list'
r = requests.get(url)


def download(url: str, page_number: int = 0):
    file_path = f'data/pages/page_{page_number}.html' 
    with open(file_path, 'wb') as downloaded_file:
        downloaded_file.write(r.content)
def explore(url: str, page_number: int = 0):
    file_path = f'data/pages/page_{page_number}.html' 
    with open(file_path, 'r') as current_page:
        root = lx.fromstring(current_page.read())
        return root


root = download(url)
auto_fullnames = root.xpath("//a[@class='text-xl leading-5 font-medium table:text-secondary table:text-base flex-1']") 
listing_status = root.xpath("//div[@class='border font-medium uppercase inline-block whitespace-nowrap text-white bg-black border-black px-1 py-0.5 text-sm rounded']")
listing_date = root.xpath("//span[@class='table:text-black']")
pages_count = int(root.xpath("//span[@class='font-medium']")[-1].text)
pages_count = pages_count // 24 + pages_count % 2
print(pages_count)
# for statuses in pages_count:
#     print(statuses.text)





print(name_divs[0].attrib)


def download_all_pages(url: str):
    download(url)
    root = explore(url)
    pages_count = int(root.xpath("//span[@class='font-medium']")[-1].text)
    pages_count = pages_count // 24 + pages_count % 2
    for i in range(1, pages_count + 1):
            download(url + f'&page={i}', i)
            if (i % 100 == 0):
                print(i)


download_all_pages(url)



